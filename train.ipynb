{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fa399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5737494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20882c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06466dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "incorrect startxref pointer(1)\n",
      "parsing for Object Streams\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('data').load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4babee1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7cd8e219-3a1a-4f37-ab4d-e5f1e8c0af4f', embedding=None, metadata={'page_label': '1', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Skin Disease Classification \\n \\n \\nContents \\n1 Overview ........................................................................................................................ 2 \\n2 Introduction .................................................................................................................. 2 \\n3 Challenges ..................................................................................................................... 3 \\n4 Benefits ........................................................................................................................... 4 \\n5 Tools and Languages ..................................................................................................... 4 \\n6 Model Comparison ...................................................................................................... 5 \\n7 Best Model ...................................................................................................................... 6 \\n8 Results Comparison ..................................................................................................... 7 \\nModel Accuracy Output ...................................................................................................... 7 \\n9 Conclusion ..................................................................................................................... 7 \\n10 Recommendations .................................................................................................... 8 \\n11 References .................................................................................................................... 8 ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4b02a35c-176a-4b1a-91e7-7b72a1673773', embedding=None, metadata={'page_label': '2', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='2  \\n1 Overview \\nThe Deep Learning Project on Skin Disease Classification aims to develop an ad- \\nvanced machine learning model to accurately classify 23 distinct skin diseases us- \\ning a combination of dermoscopic images and associated clinical symptoms. This \\nproject leverages state -of-the-art deep learning techniques to assist dermatolo - \\ngists in diagnosing skin conditions efficiently, improving diagnostic accuracy, and \\npotentially reducing the burden on healthcare systems.  By integrating convolu - \\ntional neural networks (CNNs) with symptom -based data, the project addresses \\nthe critical need for automated, reliable , and scalable diagnostic tools in derma - \\ntology. \\nThe dataset comprises images from 23 skin disease categories, such as Acne and \\nRosacea, Melanoma, and Psoriasis, sourced from a structured directory with train- \\ning and testing splits. The model processes both visual data (images resized to \\n224x224 pixels) and encoded symptom data to enhance classification performance. \\nTwo pre-trained models, EfficientNetB0 and MobileNetV2, were fine-tuned and \\nevaluated to determine the most effective architecture for this task. The project \\nemphasizes robust preprocessing, data augmentation, and performance optimiza- \\ntion to achieve high accuracy, targeting over 90% on the test set. \\nVisualization Placement: Insert the figure EfficientNetB0_training_history.png \\nhere to illustrate the training and validation performance trends of the Efficient - \\nNetB0 model. Use the caption:  â€œTraining and Validation Accuracy and Loss for \\nEfficientNetB0â€ and ensure the figure is centered and scaled to 0.8  \\n \\n2 Introduction \\nSkin diseases affect millions globally, with conditions ranging from benign issues \\nlike acne to life-threatening diseases like melanoma. Accurate diagnosis is criti- \\ncal, yet it often relies on the expertise of dermatologists, which may not always \\nbe accessible.  Deep learning offers a transformative approach by automating the \\nclassification of skin diseases using visual and clinical data. This project builds \\na deep learning framework to classify 23 skin diseases, integrating image -based \\nconvolutional neural networks with symptom-based features to improve diagnos- \\ntic precision. \\nThe motivation stems from the need to support healthcare professionals with \\nautomated tools that can handle the complexity of skin disease diagnostics.  By \\ncombining image and symptom data, the model mimics clinical decision-making ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8ac91618-81e8-46fd-bcfc-4743a9273666', embedding=None, metadata={'page_label': '3', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='3  \\nprocesses, where dermatologists assess both visual lesions and patient -reported \\nsymptoms. The project employs transfer learning with pre-trained models (Ef- \\nficientNetB0 and MobileNetV2) to leverage existing knowledge from large -scale \\ndatasets like ImageNet, fine -tuning them for the specific task of skin disease clas - \\nsification. \\nThe dataset includes 23 classes, each representing a unique skin condition, with \\nexactly 100 images per class for training to ensure balanced representation. The \\nproject also incorporates advanced techniques like data augmentation, class weight- \\ning, early stopping, and learning rate scheduling to address challenges such as \\nclass imbalance and overfitting, aiming for robust and generalizable performance. \\n \\n3 Challenges \\nDeveloping an accurate skin disease classification model presents several chal - \\nlenges: \\nâ€¢ Class Imbalance and Limited Data: Despite selecting 100 images per class, \\nsome classes had fewer images, requiring careful sampling to maintain bal- \\nance. Limited data increases the risk of overfitting, especially for complex \\nmodels. \\nâ€¢ Image Variability: Dermoscopic images vary in lighting, resolution, and \\nskin tones, complicating feature extraction and model generalization. \\nâ€¢ Symptom Integration: Encoding and integrating clinical symptoms with \\nimage data is non -trivial, as symptoms vary in relevance and spe cificity across \\ndiseases. \\nâ€¢ Model Complexity: Fine-tuning pre-trained models requires balancing the \\nretention of learned features with adaptation to the specific task, especially \\nwith a large number of classes (23). \\nâ€¢ Computational Constraints: Training deep models on high-resolution im- \\nages with symptom data demands significant computational resources, par - \\nticularly when using GPUs. \\nâ€¢ Evaluation Metrics: With 23 classes, ensuring balanced performance across \\nall classes is challenging, requiring metrics like weighted precision, recall, \\nand F1-score. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e29f591a-1983-41d4-9d54-a376609d5b67', embedding=None, metadata={'page_label': '4', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='4  \\nVisualization Placement: Insert the figure EfficientNetB0_confusion_matrix.png \\nhere to show the classification performance across all 23 classes for the Efficient- \\nNetB0 model. Use the caption: â€œConfusion Matrix for EfficientNetB0 on Test Setâ€ \\nand scale the figure to 0.9to ensure readability of class labels. \\n \\n4 Benefits \\nThe skin disease classification model offers numerous benefits: \\nâ€¢ Improved Diagnostic Efficiency: Automates preliminary diagnosis, enabling \\ndermatologists to focus on complex cases and reducing diagnostic turnaround \\ntime. \\nâ€¢ Accessibility: Provides a tool for regions with limited access to dermatolog- \\nical expertise, supporting telemedicine applications. \\nâ€¢ High Accuracy: Achieves test accuracies above 92% (EfficientNetB0: 92.38%, \\nMobileNetV2: 92.24%), demonstrating reliability for clinical use. \\nâ€¢ Scalability: The model can be extended to include more diseases or inte- \\ngrated into mobile applications for real-time diagnostics. \\nâ€¢ Comprehensive Analysis: Combines image and symptom data, mirroring \\nclinical workflows and improving diagnostic robustness. \\nâ€¢ Cost-Effectiveness: Reduces the need for extensive manual screening, po- \\ntentially lowering healthcare costs. \\n \\n5 Tools and Languages \\nThe project utilized the following tools and programming languages: \\nâ€¢ Programming Language: Python 3.8+ \\n \\nâ€¢ Libraries: \\nâ€“ PyTorch: For building, training, and evaluating deep learning models. \\nâ€“ OpenCV: For image preprocessing and resizing. \\nâ€“ NumPy and Pandas: For data manipulation and symptom encoding. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='fbdf8a0d-5995-4d5d-9915-d5d3e8e63099', embedding=None, metadata={'page_label': '5', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='5  \\nâ€“ Scikit-learn: For computing class weights, classification metrics, and \\nROC curves. \\nâ€“ Matplotlib and Seaborn: For visualizing training history, confusion \\nmatrices, and ROC curves. \\nâ€“ Torchvision: For pre-trained models and data augmentation trans- \\nforms. \\nâ€¢ Hardware: GPU (CUDA-enabled) for accelerated training; CPU fallback for \\ncompatibility. \\nâ€¢ Development Environment: Jupyter Notebook and standard Python IDEs \\n(e.g., PyCharm, VS Code). \\nâ€¢ Data Management: Custom dataset class and data loaders for efficient \\nbatch processing. \\n \\n6 Model Comparison \\nTwo pre-trained models, EfficientNetB0 and MobileNetV2, were fine-tuned for \\nthe skin disease classification task. Both models were initialized with ImageNet \\nweights and modified to incorporate symptom data through a custom architec- \\nture. The comparison focuses on architecture, performance, and suitability. \\nâ€¢ EfficientNetB0: \\nâ€“ Architecture: A lightweight, scalable CNN with compound scaling across \\ndepth, width, and resolution. It uses a combination of depthwise sepa- \\nrable convolutions and squeeze-and-excitation blocks. \\nâ€“ Parameters: Approximately 5.3 million parameters, making it efficient \\nfor deployment. \\nâ€“ Performance: Achieved a test accuracy of 92.38%, with a validation ac- \\ncuracy of 93.19% and a test loss of 0.2450. \\nâ€“ Strengths: High accuracy, robust generalization, and efficient compu- \\ntation due to optimized architecture. \\nâ€“ Weaknesses: Slightly higher computational cost compared to MobileNetV2. \\n \\nâ€¢ MobileNetV2: ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='77be8e60-423b-4dce-80af-6e7bf0c6da60', embedding=None, metadata={'page_label': '6', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='6  \\nâ€“ Architecture: Designed for mobile and resource-constrained environ- \\nments, using inverted residuals and linear bottlenecks. \\nâ€“ Parameters: Approximately 3.5 million parameters, making it more \\nlightweight than EfficientNetB0. \\nâ€“ Performance: Achieved a test accuracy of 92.24%, with a validation ac- \\ncuracy of 93.77% and a test loss of 0.2439. \\nâ€“ Strengths: Faster inference and lower resource requirements, ideal for \\nmobile applications. \\nâ€“ Weaknesses: Slightly lower test accuracy compared to EfficientNetB0. \\nVisualization Placement: Insert the figure MobileNetV2_training_history.png \\nhere to compare the training and validation performance trends of the MobileNetV2 \\nmodel. Use the caption: â€œTraining and Validation Accuracy and Loss for MobileNetV2â€ \\nand scale the figure to 0.8 \\n \\n7 Best Model \\nBased on the evaluation metrics, EfficientNetB0 is selected as the best model \\ndue to its slightly higher test accuracy (92.38% vs.  92.24%) and robust perfor - \\nmance across training, validation, and test sets.  While MobileNetV2 offers com - \\nputational efficiency, EfficientNetB0â€™s superior accuracy and generalization make \\nit more suitable for clinical applications where diagnostic precisi on is paramount. \\nThe modelâ€™s architecture, which balances depth and efficiency, allows it to capture \\ncomplex features in dermoscopic images while integrating symptom data effec - \\ntively. \\nThe EfficientNetB0 model was fine-tuned with a learning rate of 0.001, Adam op - \\ntimizer, and class -weighted cross-entropy loss to handle class imbalance.  Early \\nstopping (patience=5) and learning rate scheduling (factor=0.5, patience=3) en - \\nsured optimal convergence. The modelâ€™s performance is visualized through con - \\nfusion matrices and ROC curves, confirming its ability to distinguish between the \\n23 classes effectively. \\nVisualization Placement: Insert the figure EfficientNetB0_roc_curve.png \\nhere to demonstrate the modelâ€™s ability to distinguish between classes.  Use the \\ncaption: â€œROC Curve for EfficientNetB0 Across All Classesâ€ and scale the figure to \\n0.9 ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='6239fe38-0e8d-4006-bb0b-ff1cb2ee303b', embedding=None, metadata={'page_label': '7', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='7  \\n8 Results Comparison \\nThe performance of EfficientNetB0 and MobileNetV2 is summarized in the follow- \\ning table, based on the test set metrics: \\nTable 1: Model Performance Comparison \\n \\nModel Train Accuracy Val Accuracy Test Accuracy Test Loss \\nEfficientNetB0 99.75% 93.19% 92.38% 0.2450 \\nMobileNetV2 99.01% 93.77% 92.24% 0.2439 \\n \\nTable 2: Overall Classification Metrics (Test Set) \\n \\nModel Weighted Precision Weighted Recall Weighted F1-Score Support \\nEfficientNetB0 92.81% 92.38% 92.45% 2151 \\nMobileNetV2 92.66% 92.24% 92.29% 2151 \\n \\n \\nModel Accuracy Output \\nThe model accuracy output,  as shown in the tables above, indicates that both \\nmodels achieve high performance, with EfficientNetB0 slightly outperforming Mo- \\nbileNetV2 on the test set. The weighted F1-scores (92.45% for EfficientNetB0 and \\n92.29% for MobileNetV2) reflect balanced precision and recall, critical for multi - \\nclass classification tasks with 23 classes. \\nVisualization Placement: Insert the figure MobileNetV2_confusion_matrix.pdf \\nhere to compare the classification performance of MobileNetV2 across all 23 classes. \\nUse the caption: â€œConfusion Matrix for MobileNetV2 on Test Setâ€ and scale the fig- \\nure to 0.9 \\n \\n9 Conclusion \\nThe Deep Learning Project for Skin Disease Classification successfully developed a \\nrobust model for classifying 23 skin diseases, achieving test accuracies of 92.38% \\n(EfficientNetB0) and 92.24% (MobileNetV2).  By integrating dermoscopic images \\nwith symptom data, the project demonstrates the potential of deep learning to \\nenhance diagnostic accuracy in dermatology. EfficientNetB0 emerged as the best \\nmodel due to its superior test accuracy and generalization, making it suitable for \\nclinical applications. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5518c076-65ba-4ae0-a755-ccca6eeb0093', embedding=None, metadata={'page_label': '8', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='8  \\nThe project addressed challenges such as class imbalance, image variability, and \\nsymptom integration through careful data preprocessing, augmentation, and model \\noptimization. The use of pre-trained models, fine-tuning, and advanced training \\ntechniques like early stopping and class weighting contributed to the high per- \\nformance. Visualizations, including training history, confusion matrices, and ROC \\ncurves, provide comprehensive insights into model performance. \\n \\n10 Recommendations \\nTo further enhance the project and its applicability, the following recommenda- \\ntions are proposed: \\nâ€¢ Expand Dataset: Incorporate additional images and diverse skin types to \\nimprove model robustness and generalizability. \\nâ€¢ Real-Time Deployment: Develop a mobile or web application integrating \\nthe EfficientNetB0 model for real-time diagnostics in clinical settings. \\nâ€¢ Symptom Refinement: Enhance symptom encoding by incorporating weighted \\nsymptom relevance or patient-reported severity scores. \\nâ€¢ Ensemble Models: Explore ensemble techniques combining EfficientNetB0 \\nand MobileNetV2 to potentially boost accuracy further. \\nâ€¢ Clinical Validation: Conduct trials with dermatologists to validate model \\npredictions in real-world scenarios. \\nâ€¢ Explainability: Integrate interpretability tools (e.g., Grad-CAM) to visualize \\nmodel decision-making, increasing trust in clinical use. \\n \\n11 References \\nâ€¢ Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification \\nwith deep convolutional neural networks.  Advances in Neural Information Pro- \\ncessing Systems, 25. \\nâ€¢ Tan, M., & Le, Q. V. (2019). EfficientNet: Rethinking model scaling for convo- \\nlutional neural networks. International Conference on Machine Learning. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='dbc17275-ebb3-41a1-9be5-01b5a0ea2f41', embedding=None, metadata={'page_label': '9', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='9  \\nâ€¢ Sandler, M., et al.  (2018). MobileNetV2: Inverted residuals and linear bot - \\ntlenecks. Proceedings of the IEEE Conference on Computer Vision and Pattern \\nRecognition. \\nâ€¢ PyTorch Documentation. https://pytorch.org/docs/stable/index. \\nhtml \\nâ€¢ Scikit-learn Documentation. https://scikit-learn.org/stable/ \\n \\n13 Appendix \\n \\n\\uf0b7 Figure 1: Training curves  \\n \\n \\n \\n\\uf0b7 Figure 2: EfficientNetB0 confusion matrix  \\n \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='69616d3e-1f03-4396-a546-108df5e2b039', embedding=None, metadata={'page_label': '10', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1\\n0 \\n \\n \\n \\n \\n\\uf0b7 Figure 3: ROC curves for EfficientNetB0 \\n \\n\\uf0b7  \\n\\uf0b7 Figure 4: MobileNetV2 \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='09860b2d-f269-4fbc-b15c-91c89d360c4e', embedding=None, metadata={'page_label': '11', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1\\n1 \\n \\n \\n \\n\\uf0b7 Figure 5: MobileNetV2 confusion matrix  \\n  \\n\\uf0b7 Figure 6: MobileNet confusion matrix  \\n \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='82b55dd9-41dd-4618-b4de-94edb708e7fb', embedding=None, metadata={'page_label': '12', 'file_name': 'Report .pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Report .pdf', 'file_type': 'application/pdf', 'file_size': 1348550, 'creation_date': '2025-06-28', 'last_modified_date': '2025-06-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='1\\n2 \\n \\n \\n \\n \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='57a6eab2-ebba-4431-b666-540d79c9588e', embedding=None, metadata={'page_label': '1', 'file_name': 'Waqas Naveed AI CV.pdf', 'file_path': 'd:\\\\Self Learning\\\\Gen AI\\\\Build-Rag-on-PDF\\\\data\\\\Waqas Naveed AI CV.pdf', 'file_type': 'application/pdf', 'file_size': 347339, 'creation_date': '2025-06-28', 'last_modified_date': '2025-05-27'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='AI/ML Engineer \\n        Waqas Naveed \\n       ðŸ“ž Contact: +92 477 603854                                       ðŸ”— Portfolio: https://personal-portfolio-website-opal-five.vercel.app/                            \\n       âœ‰ Email: waqas56jb@gmail.com                                         ðŸ”— LinkedIn: linkedin.com/in/waqas-naveed-630297247 \\n       ðŸ“ Location: Faisalabad, Pakistan                                      ðŸ’» GitHub: github.com/Waqas56jb                      \\n \\nMotivated Computer Science student with a solid foundation  in Artificial Intelligence, Machine Learning, NLP,  Data Science, Data \\nEngineering and Generative AI technologies. Eager to apply technical expertise to contibute to rapid prototyping and Proof of Concepts \\n(PoCs) in Generative AI, leveraging Python and related frameworks. Seeking an opportunity to collabor ate with industry professionals \\n \\nSKILLS  \\nArtificial Intelligence \\nMachine Learning (Regression, Classification, Clustering), Deep Learning (PyTorch, TensorFlow, Keras, FastAI), LLMs (Transfor mers, \\nFine-tuning, Retrieval-Augmented Generation, Prompt Engineering, NLP), Computer Vision, Hugging Face, OpenAI, Gemini, Scikit -\\nLearn, model integration using  Flask & FastAPI, MLOps (CI/CD pipelines, Docker, MLflow), version control with GitHub & Git Bash, \\ncloud deployment on Azure & AWS \\nData Science \\nData Collection, Preprocessing, Feature Engineering, Exploratory Data Analysis, Model Training & Evaluation, Cross -Validation, \\nPredictive Analytics, Web  Scrapig Pandas, NumPy, Scikit-Learn, Matplotlib, Seaborn, TensorFlow, Keras, PyTorch, SQL, Power BI, \\nStatistical Analysis \\nEDUCATION \\nBS Computer Science                                                                                                       September 2021 â€“ June 2025 (Expected) \\nFAST National University of Computer and Emerging Sciences  \\nWORK EXPERIENCE \\nArtificial Intelligence Engineer       \\nFreelancing and Code Agentic developer team \\n\\uf0b7 Trained and fine-tuned AI and ML models to achieve high accuracy and optimal performance. \\n\\uf0b7 Built Retrieval-Augmented Generation (RAG) systems using LangChain for enhanced query responses. \\n\\uf0b7 Deployed scalable AI solutions on cloud platforms (AWS, GCP,AZURE). \\nPROJECTS \\nHealthGenics â€“ Final Year Project June 2024-2025 \\nâ€¢ Developed an AI-powered fitness and rehabilitation app focusing on body position detection, workout plans, and injury recovery. \\nâ€¢ Utilized MediaPipe for body position tracking, React Native for front-end, and Flask for backend model deployment. \\nâ€¢ Integrated for user progress visualization and designed a premium category with online transaction features. \\nAutomated Web Scraper & Email Outreach System â€“ UK Tech Company   November  2024 \\nâ€¢ Developed a dynamic web scraping tool to extract emails, phone numbers, and contact details from various websites. \\nâ€¢ Utilized Python, Scrapy, Selenium, and BeautifulSoup to handle complex, JavaScript-rendered sites. \\nâ€¢ Integrated an automated email-sending system using SMTP and organizational email services for targeted outreach. \\nEmergency Vehicle Detection System â€“ Hull University Client    December 2023 \\nâ€¢ Developed a deep learning model for detecting and classifying emergency vehicles using image data. \\nâ€¢ Utilized TensorFlow and Keras to train a CNN-based model for real-time prediction. \\nâ€¢ Improved accuracy and responsiveness to aid in automated traffic management and emergency response. \\nBLIP-2 Vision-Language Model Fine-Tuning for Image Captioning â€“ Public Project                               February 2025 \\nâ€¢ Fine-tuned the BLIP-2 VLM to generate detailed captions and visual stories from image datasets.  \\nâ€¢ Used PyTorch and HuggingFace Transformers with custom prompt-tuning and decoding strategies. \\nâ€¢ Improved caption quality by enhancing multi-modal understanding through data preprocessing and model refinement. \\nVehicle Insurance Management System â€“ Industry Project                                                                                  Aprail 2025 \\nâ€¢ Built and deployed a full-stack vehicle insurance system with policy creation, premium calculation, and claims handling.  \\nâ€¢ Integrated telematics data, fraud detection logic, and customer self-service features using Flask, Docker, and AWS EC2. \\nâ€¢ Delivered scalable cloud-based deployment and CI/CD setup for seamless updates and industry -grade reliability.  ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8864a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index.embeddings.langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mllama_index\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LangchainEmbedding\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Local Hugging Face embedding model\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'llama_index.embeddings.langchain'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Set up local Hugging Face embedding model\n",
    "embed_model = LangchainEmbedding(\n",
    "    HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    ")\n",
    "\n",
    "# Load documents from the 'data' folder\n",
    "documents = SimpleDirectoryReader('data').load_data()\n",
    "\n",
    "# Create vector index with local embeddings\n",
    "index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, show_progress=True)\n",
    "\n",
    "# Query\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is this document about?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee1699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
